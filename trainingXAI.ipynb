{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, CenterCrop\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from health_multimodal.common.visualization import plot_phrase_grounding_similarity_map\n",
    "from health_multimodal.text import get_bert_inference\n",
    "from health_multimodal.text.utils import BertEncoderType\n",
    "from health_multimodal.image import get_image_inference\n",
    "from health_multimodal.image.utils import ImageModelType\n",
    "from health_multimodal.vlp import ImageTextInferenceEngine\n",
    "from health_multimodal.image.data.io import load_image\n",
    "from health_multimodal.image.data.transforms import create_chest_xray_transform_for_inference\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report Processing with Mistral-7B Base Code\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "index = 13\n",
    "indexStart = 5500 * (index - 1)\n",
    "indexEnd = 5500 * (index*5)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", use_auth_token=\"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\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", use_auth_token=\"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\")\n",
    "\n",
    "\n",
    "paFiles = np.load('/home/csgrad/byalavar/medicalXAI/paFiles.npy', allow_pickle=True)\n",
    "paFilesPart = paFiles[indexStart:indexEnd]\n",
    "model=model.half()\n",
    "model.to(device)\n",
    "\n",
    "def extractConcepts(model,text):\n",
    "    messages = [\n",
    "    {\"role\":\"user\",\"content\":\"Given a radiology report extract fine grained atomic concepts from it and make seperate sentences for each concept. Each sentence should completely be described in a single concept. Report :  The cardiac, mediastinal and hilar contours are normal. Pulmonary vasculature is normal.  Lungs are clear. No pleural effusion or pneumothorax is present. Multiple clips are again seen projecting over the left breast.  Remote left-sided rib fractures are also re- demonstrated.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cardiac contours are normal. Mediastinal contours are normal.  Hilar contours are normal.  Pulmonary vasculature is normal.  Lungs are clear.  No pleural effusion is present.  No pneumothorax is present.  Multiple clips are seen over the left breast.  Remote left-sided rib fractures.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do the same for this report:\" + text}]\n",
    "\n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    " \n",
    "    generated_ids = model.generate(model_inputs, max_new_tokens=300, do_sample=False,pad_token_id=tokenizer.eos_token_id)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    final_response = decoded[0].split(\"assistant:\")[-1].strip()\n",
    " \n",
    "\n",
    "    sentences = final_response.split(\"[/INST]\")\n",
    "\n",
    "    return sentences[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_findings(model, file_paths, output_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    #os.makedirs(output_dir, exist_ok=True)\n",
    "    count = 0\n",
    "    for file_path in file_paths:\n",
    "        \n",
    "        \n",
    "        #print(file_path)    \n",
    "        if file_path.endswith('.txt'):\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    content = f.read()\n",
    "                    findings = re.search('FINDINGS:(.*?)(?:IMPRESSION:|$)', content, re.DOTALL)\n",
    "                    if findings:\n",
    "                        findings_text = findings.group(1).strip()\n",
    "                        output_file = os.path.join(output_dir, f'{os.path.splitext(os.path.basename(file_path))[0]}_findings.txt')\n",
    "                        \n",
    "                        if os.path.exists(output_file):\n",
    "                            count += 1\n",
    "                            continue\n",
    "\n",
    "                        output = extractConcepts(model,findings_text)\n",
    "                        output_file = os.path.join(output_dir, f'{os.path.splitext(os.path.basename(file_path))[0]}_findings.txt')\n",
    "                        \n",
    "                        # Create the output file and write the output\n",
    "                        with open(output_file, 'w') as out_f:\n",
    "                            out_f.write(output)\n",
    "                        count += 1\n",
    "                        print(count,output_file)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {file_path} not found.\")\n",
    "        else:\n",
    "            print(f\"File {file_path} is not a text file.\")\n",
    "    print(f\"Processed {count} files.\")   \n",
    "# Call the function with the input directory and output directory\n",
    "extract_findings(model,paFilesPart, '/data/bharat/XAI/txt_files_concepts2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitPath = '/home/csgrad/byalavar/medicalXAI/mimic-cxr-2.0.0-split.csv'\n",
    "labelsPath = '/home/easgrad/ajanrao/t2i/datasets/mimic/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-2.0.0-chexpert_original.csv'\n",
    "conceptFilePath = '/data/bharat/XAI/txt_files_concepts2'\n",
    "xRayFilePath = '/home/easgrad/ajanrao/t2i/datasets/mimic/physionet.org/files/mimic-cxr-jpg/2.0.0/files'\n",
    "\n",
    "#Get the splits\n",
    "df = pd.read_csv(splitPath)\n",
    "\n",
    "paFiles = np.load('paFiles.npy', allow_pickle=True)       \n",
    "paFilesTemp = np.load('paFilesTemp.npy', allow_pickle=True)       \n",
    "\n",
    "paFiles = np.append(paFiles, paFilesTemp)\n",
    "print(len(paFiles))\n",
    "#df_train = df[df['split'] == 'train']\n",
    "\n",
    "df_train = df\n",
    "\n",
    "subject_ids_in_files = [os.path.basename(path).split('_')[0] for path in paFiles]\n",
    "df_train['study_id'] = 's' + df_train['study_id'].astype(str) + '.txt'\n",
    "\n",
    "df_filtered = df_train[df_train['study_id'].isin(subject_ids_in_files)]\n",
    "\n",
    "df_filtered['study_id'] = df_filtered['study_id'].str.replace('.txt', '')\n",
    "df_filtered['study_id'] = df_filtered['study_id'].str.replace('s', '')\n",
    "totalSplit = list(df_filtered['study_id'])\n",
    "\n",
    "print(len(totalSplit))\n",
    "#Labels\n",
    "dfLabels = pd.read_csv(labelsPath)\n",
    "\n",
    "disease_columns = list(dfLabels.columns)[2:]\n",
    "\n",
    "for column in disease_columns:\n",
    "    dfLabels[column] = dfLabels[column].replace({-1: 0, 'missing': 0})\n",
    "    \n",
    "dfLabels = dfLabels.fillna(0)\n",
    "dfLabels['study_id'] = dfLabels['study_id'].astype(str)\n",
    "dfLabelsTotal = dfLabels[dfLabels['study_id'].isin(totalSplit)]\n",
    "dfLabelsTotal = dfLabelsTotal[~dfLabelsTotal['subject_id'].astype(str).str.startswith('19')]\n",
    "\n",
    "#dfLabelsTrain = dfLabelsTrain[dfLabelsTrain['Pleural Effusion'].astype(int) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(study_id, folder_path):\n",
    "    file_path = os.path.join(folder_path, f's{study_id}_findings.txt')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read().strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "dfLabelsTotal['findings'] = dfLabelsTotal['study_id'].apply(lambda x: read_text(x, conceptFilePath))\n",
    "\n",
    "dfLabelsTotal = dfLabelsTotal[dfLabelsTotal['findings'].notnull()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_jpg_files(row, root_dir):\n",
    "   \n",
    "    subject_id = row['subject_id']\n",
    "    study_id = row['study_id']\n",
    "\n",
    "  \n",
    "    dir_path = os.path.join(root_dir, f'p{str(subject_id)[:2]}', f'p{subject_id}', f's{study_id}')\n",
    "\n",
    " \n",
    "    jpg_files = glob.glob(os.path.join(dir_path, '*.jpg'))\n",
    "\n",
    " \n",
    "    if jpg_files:\n",
    "        return jpg_files[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "dfLabelsTotal['path'] = dfLabelsTotal.apply(lambda row: get_jpg_files(row, xRayFilePath), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLabelsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_zero = dfLabelsTotal[dfLabelsTotal['Pleural Effusion'] == 0]\n",
    "\n",
    "\n",
    "df_sample = df_zero.sample(n=30000, random_state=1)\n",
    "\n",
    "\n",
    "study_id_list = df_sample['study_id'].tolist()\n",
    "study_id_list = ['s' + study_id +'_findings.txt'  for study_id in study_id_list]\n",
    "\n",
    "\n",
    "print(study_id_list)\n",
    "\n",
    "\n",
    "df_one = dfLabelsTotal[dfLabelsTotal['Pleural Effusion'] == 1]\n",
    "\n",
    "df_sample = df_one.sample(n=12000, random_state=1)\n",
    "\n",
    "\n",
    "study_id_list1 = df_sample['study_id'].tolist()\n",
    "study_id_list1 = ['s' + study_id +'_findings.txt'  for study_id in study_id_list1]\n",
    "\n",
    "\n",
    "print(study_id_list1)\n",
    "\n",
    "study_id_list.extend(study_id_list1)\n",
    "print(len(study_id_list))\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "src_dir = conceptFilePath\n",
    "dst_dir = \"/data/bharat/XAI/txt_files_concepts2PE\"\n",
    "\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "count = 0\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "\n",
    "    if filename in study_id_list:\n",
    "        count = count + 1\n",
    "        shutil.copy(os.path.join(src_dir, filename), dst_dir)\n",
    "\n",
    "print(count)\n",
    "np.save('study_id_list.npy', study_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id_list = np.load('study_id_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(study_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_files(input_dir):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                # Remove numbers like 1), 2), etc.\n",
    "                content = re.sub(r'\\d+\\)', '', content)\n",
    "                content = re.sub(r'\\d+\\.', '', content)\n",
    "                # Break text into multiple lines using \".\"\n",
    "                content = content.replace('. ', '.\\n')\n",
    "\n",
    "                # Remove \"</s>\"\n",
    "                content = content.replace('</s>', '')\n",
    "\n",
    "                # Remove extra space at the start of the file\n",
    "                content = content.lstrip()\n",
    "\n",
    "                lines = content.split('\\n')\n",
    "                processed_lines = []\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if line == '' or '*' in line or '_' in line or ']]' in line or 'a.m' in line or 'p.m' in line:\n",
    "                        continue\n",
    "                    if line.endswith('is') or line.endswith('is ') or re.search(r'\\[.*\\]', line) or ('(' in line and ')' in line and 'previous' in line) or 'concept' in line or 'Concept' in line:\n",
    "                        continue\n",
    "                    words = line.split()\n",
    "                    if len(words) <= 2 or len(words) > 35:\n",
    "                        continue\n",
    "                    line = line.replace('sentence', '').replace('-', '').replace('concept', '').replace('Sentence', '')\n",
    "                    processed_lines.append(line)\n",
    "                content = '\\n'.join(processed_lines)\n",
    "\n",
    "                # Write the processed content back to the file\n",
    "                with open(file_path, 'w') as f:\n",
    "                    f.write(content)\n",
    "\n",
    "# Call the function with the path to your folder\n",
    "process_files('/data/bharat/XAI/txt_files_concepts2PE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "dir_path = '/data/bharat/XAI/txt_files_concepts2PE'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "files = [f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))]\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f.replace('_findings.txt','').replace('s','') for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dfFinal= dfLabelsTotal[dfLabelsTotal['study_id'].isin(files)]\n",
    "dfFinal = dfFinal.reset_index(drop=True)\n",
    "print(dfFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(study_id, folder_path):\n",
    "    file_path = os.path.join(folder_path, f's{study_id}_findings.txt')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read().strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "dfFinal['findings'] = dfFinal['study_id'].apply(lambda x: read_text(x, '/data/bharat/XAI/txt_files_concepts2PE'))\n",
    "#dfFinal = dfFinal.dropna(subset=['findings'])\n",
    "\n",
    "print(dfFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal.to_csv('dfFinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = pd.read_csv('dfFinal.csv')\n",
    "dfFinal = dfFinal.dropna(subset=['findings'])\n",
    "dfFinal = dfFinal.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_id                    0\n",
      "study_id                      0\n",
      "Atelectasis                   0\n",
      "Cardiomegaly                  0\n",
      "Consolidation                 0\n",
      "Edema                         0\n",
      "Enlarged Cardiomediastinum    0\n",
      "Fracture                      0\n",
      "Lung Lesion                   0\n",
      "Lung Opacity                  0\n",
      "No Finding                    0\n",
      "Pleural Effusion              0\n",
      "Pleural Other                 0\n",
      "Pneumonia                     0\n",
      "Pneumothorax                  0\n",
      "Support Devices               0\n",
      "findings                      0\n",
      "path                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count = dfFinal.isna().sum()\n",
    "\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conceptList = dfFinal['findings'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptLists = [i.split('\\n') for i in conceptList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331495\n"
     ]
    }
   ],
   "source": [
    "totalCount = 0\n",
    "\n",
    "for i in conceptLists:\n",
    "    totalCount = totalCount + len(i)\n",
    "\n",
    "print(totalCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_top_100_recurring_strings(lists_of_lists):\n",
    "    # Flatten the list of lists into a single list\n",
    "    all_strings = [item for sublist in lists_of_lists for item in sublist]\n",
    "\n",
    "    string_counts = Counter(all_strings)\n",
    "\n",
    "    top_100_strings = string_counts.most_common(200)\n",
    "    # Extract just the strings from the top 100\n",
    "    top_100_strings_only = [string for string, count in top_100_strings]\n",
    "    return top_100_strings_only\n",
    "\n",
    "\n",
    "topRecLists = find_top_100_recurring_strings(conceptLists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19976"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_lists_with_queries(query_strings, lists_of_lists):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for ref_list in lists_of_lists:\n",
    "\n",
    "        matches = sum(1 for query in query_strings if query in ref_list)\n",
    "\n",
    "        if matches >= 2:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "count_lists_with_queries(topRecLists,conceptLists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices_with_queries(query_strings, lists_of_lists):\n",
    "  \n",
    "    matching_indices = []\n",
    "\n",
    "    for index, ref_list in enumerate(lists_of_lists):\n",
    "\n",
    "        matches = sum(1 for query in query_strings if query in ref_list)\n",
    "\n",
    "        if matches >= 2:\n",
    "            matching_indices.append(index)\n",
    "    return matching_indices\n",
    "\n",
    "\n",
    "matching_indices = find_indices_with_queries(topRecLists, conceptLists)\n",
    "print(matching_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No pneumothorax is present.',\n",
       " 'No pleural effusion is present.',\n",
       " 'Lung volumes are low.',\n",
       " 'Heart size is normal.',\n",
       " 'Lungs are clear.',\n",
       " 'No pneumothorax is detected.',\n",
       " 'No focal consolidation is present.',\n",
       " 'Cardiomediastinal silhouette is normal.',\n",
       " 'No pulmonary edema is present.',\n",
       " 'Mediastinal contours are normal.',\n",
       " 'Hilar contours are normal.',\n",
       " 'No pleural effusions are present.',\n",
       " 'No large pleural effusion is present.',\n",
       " 'No pneumothorax is identified.',\n",
       " 'Bony structures are intact.',\n",
       " 'Cardiomediastinal silhouette is unchanged.',\n",
       " 'Cardiomediastinal silhouette is stable.',\n",
       " 'Cardiomediastinal contours are stable.',\n",
       " 'Pulmonary vasculature is normal.',\n",
       " 'Hilar contours are unremarkable.',\n",
       " 'Mediastinal contours are unremarkable.',\n",
       " 'Right lung is clear.',\n",
       " 'Cardiac silhouette is enlarged.',\n",
       " 'Bilateral pleural effusions are present.',\n",
       " 'Bibasilar atelectasis is present.',\n",
       " 'Cardiomediastinal contours are normal.',\n",
       " 'Small bilateral pleural effusions are present.',\n",
       " 'Low lung volumes are present.',\n",
       " 'Mediastinal contours are unchanged.',\n",
       " 'No pleural effusion is detected.',\n",
       " 'Left lung is clear.',\n",
       " 'Mild pulmonary edema is present.',\n",
       " 'Heart size is mildly enlarged.',\n",
       " 'Cardiomediastinal silhouette is within normal limits.',\n",
       " 'No pneumothoraces are present.',\n",
       " 'Hilar contours are stable.',\n",
       " 'No pneumothorax is seen.',\n",
       " 'Heart is mildly enlarged.',\n",
       " 'No pneumonia is present.',\n",
       " 'Heart size is within normal limits.',\n",
       " 'Hilar contours are unchanged.',\n",
       " 'Mediastinal contours are stable.',\n",
       " 'No acute osseous abnormalities are present.',\n",
       " 'No pulmonary edema is observed.',\n",
       " 'Cardiac silhouette is mildly enlarged.',\n",
       " 'Pulmonary vascular congestion is present.',\n",
       " 'There is no significant change between the current and previous study.',\n",
       " 'Cardiac contours are normal.',\n",
       " 'Cardiomediastinal silhouette is unremarkable.',\n",
       " 'No pleural effusion is seen.',\n",
       " 'Mild pulmonary vascular congestion is present.',\n",
       " 'No pleural effusions are detected.',\n",
       " 'The cardiomediastinal silhouette is normal.',\n",
       " 'No acute osseous abnormalities are detected.',\n",
       " 'No consolidation is present.',\n",
       " 'Cardiomegaly is stable.',\n",
       " 'Cardiac silhouette size is normal.',\n",
       " 'No pleural effusion or pneumothorax is present.',\n",
       " 'Cardiomegaly is present.',\n",
       " 'Pulmonary vascularity is normal.',\n",
       " 'Hilar contours are within normal limits.',\n",
       " 'Moderate cardiomegaly is present.',\n",
       " 'Mild cardiomegaly is present.',\n",
       " 'Small left pleural effusion is present.',\n",
       " 'No focal consolidation is observed.',\n",
       " 'Pulmonary vasculature is not engorged.',\n",
       " 'Lungs are hyperinflated.',\n",
       " 'Heart is normal in size.',\n",
       " 'No pneumothorax present.',\n",
       " 'No pleural effusion is identified.',\n",
       " 'The heart size is normal.',\n",
       " 'Nasogastric tube has been removed.',\n",
       " 'Cardiac silhouette is normal.',\n",
       " 'Cardiac size is normal.',\n",
       " 'The lungs are clear.',\n",
       " 'Aorta is tortuous.',\n",
       " 'Patient has been extubated.',\n",
       " 'Previous radiograph shows no relevant changes.',\n",
       " 'Lungs are well expanded.',\n",
       " 'Cardiac silhouette size is unchanged.',\n",
       " 'No focal consolidation is identified.',\n",
       " 'No focal consolidation is seen.',\n",
       " 'Cardiac and mediastinal silhouettes are stable.',\n",
       " 'Mediastinal contours are within normal limits.',\n",
       " 'Lung volumes remain low.',\n",
       " 'Cardiomegaly is moderate.',\n",
       " 'Cardiomegaly is unchanged.',\n",
       " 'Endotracheal tube position is unchanged.',\n",
       " 'No pulmonary edema.',\n",
       " 'Cardiac silhouette size is borderline.',\n",
       " 'Heart is moderately enlarged.',\n",
       " 'No pleural effusions.',\n",
       " 'No pneumothorax is observed.',\n",
       " 'Bronchovascular structures are crowded.',\n",
       " 'No new parenchymal opacities are present.',\n",
       " 'Imaged osseous structures are intact.',\n",
       " 'Right hemidiaphragm is elevated.',\n",
       " 'Median sternotomy wires are intact.',\n",
       " 'Lung volumes are relatively low.',\n",
       " 'Osseous structures are unremarkable.',\n",
       " 'Monitoring and support devices remain constant.',\n",
       " 'Lung volumes are normal.',\n",
       " 'No large pleural effusion is detected.',\n",
       " 'Lungs appear clear.',\n",
       " 'No vascular congestion is present.',\n",
       " 'Endotracheal tube has been removed.',\n",
       " 'Bony structures appear intact.',\n",
       " 'The left lung is clear.',\n",
       " 'No acute osseous abnormality is detected.',\n",
       " 'Heart size is moderately enlarged.',\n",
       " 'Cardiac contours are unchanged.',\n",
       " 'A small left pleural effusion is present.',\n",
       " 'No large effusion is present.',\n",
       " 'Small right pleural effusion is present.',\n",
       " 'Heart is enlarged.',\n",
       " 'Heart size is stable.',\n",
       " 'No definite pleural effusion is present.',\n",
       " 'The cardiomediastinal silhouette is stable.',\n",
       " 'Osseous structures are intact.',\n",
       " 'Previous study was compared.',\n",
       " 'No large pleural effusions are present.',\n",
       " 'Cardiac contours are stable.',\n",
       " 'Mediastinal and hilar contours are unchanged.',\n",
       " 'No overt pulmonary edema is present.',\n",
       " 'No pleural effusion.',\n",
       " 'The right lung is clear.',\n",
       " 'Cardiomediastinal contours are unchanged.',\n",
       " 'Pulmonary edema is present.',\n",
       " 'Mediastinal contour is normal.',\n",
       " 'No overt pulmonary edema is observed.',\n",
       " 'Cardiomediastinal contours are unremarkable.',\n",
       " 'Right pleural effusion is present.',\n",
       " 'Upper abdomen is unremarkable.',\n",
       " 'Lungs are clear without focal consolidation.',\n",
       " 'No acute osseous abnormalities are identified.',\n",
       " 'No acute osseous abnormalities are noted.',\n",
       " 'Lungs are well expanded and clear.',\n",
       " 'No evidence of pneumothorax.',\n",
       " 'Cardiac silhouette appearance is unchanged.',\n",
       " 'No pneumonia is detected.',\n",
       " 'No pulmonary vascular congestion is present.',\n",
       " 'No pleural effusion or pneumothorax is detected.',\n",
       " 'The cardiomediastinal silhouette is unchanged.',\n",
       " 'Patient has undergone median sternotomy.',\n",
       " 'Left pleural effusion is present.',\n",
       " 'No acute osseous abnormalities are observed.',\n",
       " 'Mediastinal and hilar contours are unremarkable.',\n",
       " 'Mild bibasilar atelectasis is present.',\n",
       " 'Patient is intubated.',\n",
       " 'Mild pulmonary vascular congestion is noted.',\n",
       " 'Bibasilar atelectasis is noted.',\n",
       " 'Cardiac silhouette is normal in size.',\n",
       " 'Heart size is enlarged.',\n",
       " 'No signs of pulmonary edema are observed.',\n",
       " 'Retrocardiac atelectasis is present.',\n",
       " 'Previous radiograph shows no changes.',\n",
       " 'Lungs are otherwise clear.',\n",
       " 'No evidence of pneumonia.',\n",
       " 'No focal consolidation is noted.',\n",
       " 'Mediastinal and hilar contours are normal.',\n",
       " 'Mediastinal and hilar contours are stable.',\n",
       " 'Cardiomediastinal contours are within normal limits.',\n",
       " 'Comparison is made to prior study from a specific date.',\n",
       " 'No evidence of pneumothorax is present.',\n",
       " 'Mediastinal contour is unremarkable.',\n",
       " 'Moderate pulmonary edema is present.',\n",
       " 'Pleural surfaces are normal.',\n",
       " 'There is no relevant change since the last radiograph.',\n",
       " 'Mild cardiomegaly is noted.',\n",
       " 'Cardiac silhouette is moderately enlarged.',\n",
       " 'No signs of pneumonia are present.',\n",
       " 'Aortic knob is calcified.',\n",
       " 'No new consolidation is present.',\n",
       " 'No effusion is present.',\n",
       " 'No large pleural effusion or pneumothorax is present.',\n",
       " 'Lung volumes have decreased.',\n",
       " 'The heart is mildly enlarged.',\n",
       " 'Monitoring and support devices are unchanged.',\n",
       " 'Left retrocardiac opacity is present.',\n",
       " 'Heart size is unchanged.',\n",
       " 'Previous radiograph shows no change.',\n",
       " 'ET tube has been removed.',\n",
       " 'Monitoring and support devices from previous study are still in place.',\n",
       " 'No pneumothorax detected.',\n",
       " 'Heart is of normal size.',\n",
       " 'A small right pleural effusion is present.',\n",
       " 'No edema is present.',\n",
       " 'No focal consolidation is present in the lungs.',\n",
       " 'Single frontal view of the chest was obtained.',\n",
       " 'Mediastinal silhouettes are unremarkable.',\n",
       " 'No pneumothorax identified.',\n",
       " 'NG tube has been removed.',\n",
       " 'Bibasilar opacities are present.',\n",
       " 'Tracheostomy tube is present.',\n",
       " 'No pleural effusion or pneumothorax.',\n",
       " 'No large pneumothorax is present.',\n",
       " 'NG tube is in the stomach.',\n",
       " 'Monitoring and support devices remain unchanged.',\n",
       " 'Lung volumes are reduced.',\n",
       " 'Cardiac silhouette size remains unchanged.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topRecLists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topRecLists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_concepts = topRecLists\n",
    "\n",
    "with open('unique_concepts_filtered.txt', 'w') as f:\n",
    "\n",
    "    for line in unique_concepts:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_dataframe_and_findings(df, topRecLists, matching_indices):\n",
    "\n",
    "    filtered_df = df.iloc[matching_indices].copy(deep=True)\n",
    "    \n",
    "\n",
    "    for index, row in filtered_df.iterrows():\n",
    " \n",
    "        findings_list = row['findings'].split(\"\\n\")\n",
    "\n",
    "        \n",
    "        filtered_findings = [word for word in findings_list if word in topRecLists]\n",
    "\n",
    "        filtered_df.at[index, 'findings'] = '\\n'.join(filtered_findings,)\n",
    "        \n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "filtered_df = filter_dataframe_and_findings(dfFinal, topRecLists, matching_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    15878\n",
      "1.0     4098\n",
      "Name: Pleural Effusion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = filtered_df['Pleural Effusion'].value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_copy = filtered_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_replacement_dict={'No focal consolidation':'No focal consolidation is present.',\n",
    "                      'No pleural effusion':'No pleural effusion is present.',\n",
    "                      'Cardiomediastinal silhouette':'Cardiomediastinal silhouette is normal.',\n",
    "                      'No pneumothorax':'No pneumothorax is present.',\n",
    "                      'Hilar contours':'Hilar contours are normal.',\n",
    "                      'Mediastinal':'Cardiomediastinal silhouette is normal.',\n",
    "                      'No pneumonia':'No pneumonia is present.',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `df` is your DataFrame and `column_name` is the name of the column containing the concepts\n",
    "# `ref_replacement_dict` is your reference and replacement dictionary\n",
    "\n",
    "for index, row in filtered_df_copy.iterrows():\n",
    "    # Split the string by '\\n' to get individual concepts\n",
    "    concepts = row['findings'].split('\\n')\n",
    "    # Replace each concept if it exists in the reference dictionary\n",
    "    print(concepts)\n",
    "    replaced_concepts = [next((ref_replacement_dict[key] for key in ref_replacement_dict if key.lower() in concept.lower()), concept) for concept in concepts]\n",
    "    # Join the concepts back together with '\\n' and update the DataFrame\n",
    "    filtered_df_copy.at[index, 'findings'] = '\\n'.join(replaced_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No focal consolidation is present.\\nNo pleural effusion is present.\\nNo pneumothorax is present.\\nCardiomediastinal silhouette is normal.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_copy.iloc[0]['findings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptList = filtered_df_copy['findings'].tolist()\n",
    "conceptLists = [i.split('\\n') for i in conceptList]\n",
    "\n",
    "topRecLists = set(item for sublist in conceptLists for item in sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topRecLists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_unique_concepts(input_dir):\n",
    "    unique_concepts = {}\n",
    "\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    count = count + len(lines)\n",
    "                    for line in lines:\n",
    "                        unique_concepts[line.strip()] = None\n",
    "    print(count)\n",
    "\n",
    "\n",
    "    unique_concepts = list(unique_concepts.keys())\n",
    "\n",
    "    return unique_concepts\n",
    "\n",
    "\n",
    "unique_concepts = get_unique_concepts('/data/bharat/XAI/txt_files_concepts2PE')\n",
    "\n",
    "\n",
    "\n",
    "with open('unique_concepts.txt', 'w') as f:\n",
    "\n",
    "    for line in unique_concepts:\n",
    "        f.write(line + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_concepts.txt', 'r') as f:\n",
    "\n",
    "    unique_concepts = f.readlines()\n",
    "unique_concepts = [concept.strip() for concept in unique_concepts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170941"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_concepts = topRecLists\n",
    "\n",
    "with open('unique_concepts_filtered.txt', 'w') as f:\n",
    "    # Write each line to the file\n",
    "    for line in unique_concepts:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "unique_concepts = [concept.strip() for concept in unique_concepts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /tmp/biovil_image_resnet50_proj_size_128.pt\n"
     ]
    }
   ],
   "source": [
    "#Load BERT and Image Models\n",
    "\n",
    "text_inference = get_bert_inference(BertEncoderType.CXR_BERT)\n",
    "image_inference = get_image_inference(ImageModelType.BIOVIL)\n",
    "\n",
    "image_text_inference = ImageTextInferenceEngine(\n",
    "    image_inference_engine=image_inference,\n",
    "    text_inference_engine=text_inference,\n",
    ")\n",
    "\n",
    "tempConcepts = copy.deepcopy(unique_concepts)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "embeddings = torch.zeros((len(tempConcepts), 128))\n",
    "embeddings = embeddings.to(device)\n",
    "image_text_inference.to(device)\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "#Get BERT Embeddings for the concepts\n",
    "for i in range(0, len(tempConcepts), batch_size):\n",
    "    batch_concepts = tempConcepts[i:i+batch_size]\n",
    "    batch_embeddings = image_text_inference.text_inference_engine.get_embeddings_from_prompt(batch_concepts)\n",
    "    embeddings[i:i+batch_size] = batch_embeddings\n",
    "\n",
    "\n",
    "#embeddings = embeddings.half()\n",
    "torch.save(embeddings, 'conceptEmbeddings.pt')\n",
    "#parts = torch.chunk(embeddings, 16, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load('conceptEmbeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.half()\n",
    "embeddings = embeddings.to(device)\n",
    "embeddings = nn.functional.normalize(embeddings, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([147, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similairity Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeDict = {}\n",
    "\n",
    "threshold = 0.90\n",
    "\n",
    "for i in range(0,embeddings.shape[0]):\n",
    "    temp= torch.cosine_similarity(embeddings[i].unsqueeze(0), embeddings, dim=-1)\n",
    "    #print(temp.shape)\n",
    "    #break\n",
    "\n",
    "    mask = (temp > threshold)\n",
    "    length = embeddings.shape[0]\n",
    "\n",
    "\n",
    "    midpoint = i\n",
    "    \n",
    "\n",
    "    tensor = torch.cat([torch.ones(midpoint), torch.zeros(length - midpoint)]).to(device)\n",
    "\n",
    "    mask = mask * tensor\n",
    "    indices = torch.nonzero(mask,as_tuple=True)\n",
    "    if(indices[0].shape[0]>0):\n",
    "        removeDict.setdefault(i, []).append(indices[0])\n",
    "    # for j in range(0,i+1):\n",
    "    #     if(i!=j):\n",
    "    #         if temp[j].item() > 0.995:\n",
    "    #             removeDict.setdefault(i, []).append(j)\n",
    "    if(i%100==0 and i!=0):\n",
    "        print(i)\n",
    "        \n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91931"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(removeDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92287"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempList1 = []\n",
    "tempList2 = []\n",
    "\n",
    "for i in removeDict.keys():\n",
    "    for j in removeDict[i][0]:\n",
    "        #if(j.item() not in removeDict.keys()):\n",
    "         #print(unique_concepts[j.item()],unique_concepts[i],i,j.item())\n",
    "         tempList1.append(unique_concepts[i])\n",
    "         tempList2.append(unique_concepts[j.item()])\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71205941"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tempList1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i,j in zip(tempList1,tempList2):\n",
    "    print(i,j)\n",
    "    count = count + 1\n",
    "    if(count>1000):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(tempList1)):\n",
    "    tempList1[i] = tempList1[i].strip()\n",
    "    tempList2[i] = tempList2[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "line_dict = {line: replacement for line, replacement in zip(tempList2, tempList1)}\n",
    "\n",
    "txt_files = [f for f in os.listdir('/data/bharat/XAI/txt_files_concepts2PE') if f.endswith('.txt')]\n",
    "\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "\n",
    "# Process each file\n",
    "for filename in txt_files:\n",
    "    print(count0)\n",
    "    count0 += 1\n",
    "    \n",
    "    full_path = os.path.join('/data/bharat/XAI/txt_files_concepts2PE', filename)\n",
    "    #print(full_path)\n",
    "    \n",
    "    with open(full_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        stripped_line =  line.strip()\n",
    "        \n",
    "        if stripped_line in line_dict:\n",
    "      \n",
    "            count1 += 1\n",
    "            lines[i] = line_dict[stripped_line] + '\\n'\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    with open(full_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160725"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptBank = unique_concepts\n",
    "embeddingsCB = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conceptBank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptBank = [str(element) for element in conceptBank]\n",
    "#embeddingsCB =embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# X = filtered_df_copy.drop(['Pleural Effusion'], axis=1)  # Features\n",
    "# y = filtered_df_copy['Pleural Effusion']  # Labels\n",
    "\n",
    "# # Apply RandomOverSampler\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# # Combine resampled features and labels back into a DataFrame\n",
    "# resampled_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "# # Now, use resampled_df to create your CustomDataset\n",
    "# totalDataset = CustomDataset(resampled_df, '/home/easgrad/ajanrao/t2i/datasets/mimic/physionet.org/files/mimic-cxr-jpg/2.0.0/files', conceptBank)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, root_dir,conceptBank, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.conceptBank = conceptBank\n",
    "        self.transform =  create_chest_xray_transform_for_inference(resize=512, center_crop_size=512)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "\n",
    "        jpg_files = self.df.iloc[idx]['path']\n",
    "        #print(jpg_files)\n",
    "       \n",
    "        #print(jpg_files)\n",
    "        if jpg_files:\n",
    "            image = load_image(Path(jpg_files))\n",
    "            image = self.transform(image)\n",
    "            #image = jpg_files[0]\n",
    "        else:\n",
    "            image = None\n",
    "\n",
    "        # Get the label\n",
    "        #print(self.df.iloc[idx, 2:].values)\n",
    "        \n",
    "        labels = torch.tensor(self.df.iloc[idx, 11].astype(float))  # Replace 'label' with your actual label column name\n",
    "        #print(labels)\n",
    "        conceptLabels = self.df.loc[idx, 'findings']\n",
    "        #print(self.df.loc[idx, 'subject_id'],self.df.loc[idx, 'study_id'],conceptLabels)\n",
    "        #print(type(image))\n",
    "        return image, labels,conceptLabels\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return list(images), torch.stack(labels)\n",
    "\n",
    "# Create DataLoader\n",
    "totalDataset = CustomDataset(filtered_df_copy, '/home/easgrad/ajanrao/t2i/datasets/mimic/physionet.org/files/mimic-cxr-jpg/2.0.0/files',conceptBank)\n",
    "\n",
    "train_size = int(0.85 * len(totalDataset))  # 80% for training\n",
    "test_size = len(totalDataset) - train_size  # 20% for testing\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# Split the dataset\n",
    "trainDataset, testDataset = random_split(totalDataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for train and test sets\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "testDataLoader = DataLoader(testDataset, batch_size=1, shuffle=False, pin_memory=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity Check 1\n",
    "testDataLoader = DataLoader(testDataset, batch_size=64, shuffle=False, pin_memory=False, num_workers=1)\n",
    "a,b,c = next(iter(testDataLoader))\n",
    "\n",
    "#Sanity Check 2\n",
    "row_with_x = filtered_df_copy[filtered_df_copy['study_id'] == 56401460]\n",
    "print(row_with_x['findings'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inference = get_bert_inference(BertEncoderType.CXR_BERT)\n",
    "image_inference = get_image_inference(ImageModelType.BIOVIL)\n",
    "\n",
    "image_text_inference = ImageTextInferenceEngine(\n",
    "    image_inference_engine=image_inference,\n",
    "    text_inference_engine=text_inference,\n",
    ")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_text_inference.to(device)\n",
    "\n",
    "\n",
    "#Freezing Weights of certain layer in the image encoder and BERT\n",
    "\n",
    "def freezeWeghts(imageEncoder,layerNumber):\n",
    "    count = 0\n",
    "    for i,j in imageEncoder.named_parameters():\n",
    "        if(count>=layerNumber):\n",
    "            j.requires_grad = True\n",
    "        else:\n",
    "            j.requires_grad = False\n",
    "        #print(i,j.requires_grad,count)\n",
    "        count = count + 1\n",
    "    return imageEncoder\n",
    "\n",
    "imageEncoder = image_text_inference.image_inference_engine.model\n",
    "bert = image_text_inference.text_inference_engine.model\n",
    "\n",
    "imageEncoder = freezeWeghts(imageEncoder,170)\n",
    "bert = freezeWeghts(bert,190)\n",
    "\n",
    "\n",
    "\n",
    "class resConnect(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(resConnect, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class fc(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(fc, self).__init__()\n",
    "        self.fc = nn.Linear(embeddingsCB.shape[0], 2)\n",
    "        #self.fc = nn.Linear(128, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "resNet = resConnect()\n",
    "resNet.to(device)\n",
    "\n",
    "fcNet = fc()\n",
    "fcNet.to(device)\n",
    "\n",
    "embeddingsCB = nn.functional.normalize(embeddingsCB, dim=-1)\n",
    "\n",
    "#fcNet = fcNet.half()\n",
    "\n",
    "# #print(fcNet)\n",
    "# count =0\n",
    "# for name,param in fcNet.named_parameters():\n",
    "#    if(name == 'fc.weight'):\n",
    " \n",
    "#     #print(param.shape,param.data) \n",
    "#     param.data = fcWeights\n",
    "#     #print(\"----------------------------\")\n",
    "#     #print(param.shape,param.data)\n",
    "#     count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainable_params = [p.numel() for p in imageEncoder.parameters() if p.requires_grad]\n",
    "\n",
    "\n",
    "print(sum(trainable_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i,j in imageEncoder.named_parameters():\n",
    " \n",
    " print(i,j.requires_grad,count)\n",
    " count = count + 1\n",
    "\n",
    "count = 0\n",
    "for i,j in bert.named_parameters():\n",
    " \n",
    " print(i,j.requires_grad,count)\n",
    " count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTensors = None\n",
    "labelTensors = None\n",
    "conceptLabelTensors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Tensor Extraction\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    " acc = 0  \n",
    " running_loss = 0.0\n",
    " running_corrects = 0\n",
    " clLoss = []\n",
    " conLoss = []\n",
    " for tdi,data in tqdm(enumerate(trainDataLoader)):\n",
    "    print(tdi)\n",
    "    #print(\"Check1\")\n",
    "    images,labels,conceptLabels = data\n",
    "    images = images.half()\n",
    "    \n",
    "    #print(images.shape,labels.shape)\n",
    "    #print(conceptLabels,conceptLabels.shape)\n",
    "   # print(\"Check1\")\n",
    "    #print(conceptLabels.shape)\n",
    "    #print(conceptLabels)\n",
    "    conceptLabels = [[s.lstrip() for s in cl.split('\\n')] for cl in conceptLabels]\n",
    "\n",
    "    \n",
    "    #break  \n",
    "    #print(\"Check2\")\n",
    "    indices = []\n",
    "    #print(conceptLabels[0],conceptLabels[1])\n",
    "    for j in range(0,len(conceptLabels)):\n",
    "        indices.append([conceptBank.index(str(s)) for s in conceptLabels[j] if str(s) in conceptBank])\n",
    "   # print(\"Check3\")\n",
    "    \n",
    "    #break\n",
    "    #labelConcepts = torch.tensor(indices)\n",
    "    labelConcepts = [torch.tensor(lst, dtype=torch.long) for lst in indices]\n",
    "  \n",
    "    #print(labelConcepts)\n",
    " \n",
    "    #print(conceptLabelTensors)\n",
    "    if(imageTensors is None):\n",
    "        imageTensors = images\n",
    "        labelTensors = labels\n",
    "        conceptLabelTensors = labelConcepts\n",
    "    else:\n",
    "        imageTensors = torch.cat((imageTensors,images),0)\n",
    "        labelTensors = torch.cat((labelTensors,labels),0)\n",
    "        conceptLabelTensors.extend(labelConcepts)\n",
    "    \n",
    "\n",
    "if(True):\n",
    "        torch.save(imageTensors, 'imageTensors.pt')\n",
    "        torch.save(labelTensors, 'labelTensors.pt')\n",
    "        torch.save(conceptLabelTensors, 'conceptLabelTensors.pt')\n",
    "        imageTensors = None\n",
    "        labelTensors = None\n",
    "        conceptLabelTensors = None\n",
    "        gc.collect()\n",
    "\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTensors = torch.load('imageTensors.pt').to(device)\n",
    "labelTensors = torch.load('labelTensors.pt').to(device)\n",
    "conceptLabelTensors = torch.load('conceptLabelTensors.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16979, 3, 512, 512])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageTensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTensors = labelTensors.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "alpha = 2\n",
    "\n",
    "optimizer = torch.optim.AdamW([{\"params\":fcNet.parameters(), \"lr\":0.005,\"weight_decay:\":0.0001},\n",
    "                              {\"params\":resNet.parameters(), \"lr\":0.005,\"weight_decay\":0.0001},\n",
    "                              {\"params\":imageEncoder.parameters(), \"lr\":0.00001,\"weight_decay\":0.0001},\n",
    "                              {\"params\":bert, \"lr\":0.000001,\"weight_decay\":0.00001}]) \n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#lossFunctionConcepts = nn.MSELoss(reduction='sum')\n",
    "lossFunctionConcepts = nn.L1Loss(reduction='sum')\n",
    "\n",
    "batchSize = 128\n",
    "\n",
    "\n",
    "conceptLearning = False\n",
    "classLearning = False\n",
    "\n",
    "for e in range(0,epochs):\n",
    "\n",
    " acc = 0  \n",
    " running_loss = 0.0\n",
    " running_corrects = 0\n",
    " clLoss = []\n",
    " conLoss = []\n",
    "\n",
    " count = 0\n",
    " count1 = 0 \n",
    "\n",
    " for tdi in range(0,imageTensors.shape[0],batchSize):\n",
    "\n",
    "\n",
    "    if(tdi<20000):\n",
    "      \n",
    "      images = imageTensors[count:count+batchSize].to(device)\n",
    "      labels = labelTensors[count:count+batchSize].to(device)\n",
    "      labelConcepts =  conceptLabelTensors[count:count+batchSize]\n",
    "      count = count + images.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    images = images.to(torch.float32)\n",
    "\n",
    "    imageEmbeddings = imageEncoder(images).projected_global_embedding\n",
    "\n",
    "    \n",
    "\n",
    "    resOut = resNet(imageEmbeddings)\n",
    "\n",
    "    imageEmbeddings = 0.85*imageEmbeddings + 0.15*resOut\n",
    "\n",
    "    imageEmbeddings = nn.functional.normalize(imageEmbeddings, dim=-1)\n",
    "    \n",
    "  \n",
    "    embeddingsCB = bert.get_embeddings_from_prompt(conceptBank)\n",
    " \n",
    "\n",
    "    \n",
    "    conceptScores = torch.mm(imageEmbeddings,embeddingsCB.t())\n",
    "\n",
    "    output = fcNet(conceptScores)\n",
    "    #output = fcNet(imageEmbeddings)\n",
    "\n",
    "    \n",
    "\n",
    "    output = output.to(torch.float32)\n",
    "    labels = labels.to(torch.long)\n",
    "\n",
    "    conceptScoresCopy = conceptScores.clone().detach().to(device)\n",
    "\n",
    "    maxValue =  torch.max(conceptScoresCopy,dim=1)[0]\n",
    "\n",
    "    \n",
    "    for i, idx in enumerate(labelConcepts):\n",
    "\n",
    "      conceptScoresCopy[i, idx] = torch.tensor(0.90)\n",
    "     \n",
    "    \n",
    "\n",
    "\n",
    "    lossClassification = lossFunction(output, labels)\n",
    "\n",
    "    lossConcepts = lossFunctionConcepts(conceptScores,conceptScoresCopy)\n",
    "\n",
    "    if(conceptLearning):\n",
    "     loss = alpha*lossConcepts\n",
    "    elif(classLearning):\n",
    "      loss = lossClassification\n",
    "    else:\n",
    "      loss = lossClassification + alpha*lossConcepts\n",
    "\n",
    "    clLoss.append(lossClassification.item())\n",
    "    conLoss.append(lossConcepts.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "   \n",
    "    optimizer.step()\n",
    "  \n",
    "    \n",
    "\n",
    "    running_loss += lossConcepts.item()\n",
    "\n",
    "\n",
    "    #running_corrects += torch.sum(torch.argmax(output, dim=1) == labels).item()\n",
    "\n",
    "\n",
    "    \n",
    "    acc = acc + torch.sum(torch.argmax(output,dim=1) == labels).item()\n",
    "   \n",
    " print(\"Accuracy: \", acc/imageTensors.shape[0],\"Loss:\", running_loss/imageTensors.shape[0])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor Extraction Test\n",
    "\n",
    "\n",
    "imageTensorsTest = None\n",
    "labelTensorsTest = None\n",
    "conceptLabelTensorsTest = None\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "alpha = 2\n",
    "\n",
    "optimizer = torch.optim.Adam([{\"params\":fcNet.parameters(), \"lr\":0.001},\n",
    "                              {\"params\":imageEncoder.parameters(), \"lr\":0.0005,\"weight_decay\":0.00001}])\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "lossFunctionConcepts = nn.L1Loss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    " acc = 0  \n",
    " running_loss = 0.0\n",
    " running_corrects = 0\n",
    " clLoss = []\n",
    " conLoss = []\n",
    " for tdi,data in tqdm(enumerate(testDataLoader)):\n",
    "    print(tdi)\n",
    "    #print(\"Check1\")\n",
    "    images,labels,conceptLabels = data\n",
    "    images = images.half()\n",
    "    \n",
    "    #print(images.shape,labels.shape)\n",
    "    #print(conceptLabels,conceptLabels.shape)\n",
    "   # print(\"Check1\")\n",
    "    #print(conceptLabels.shape)\n",
    "    #print(conceptLabels)\n",
    "    conceptLabels = [[s.lstrip() for s in cl.split('\\n')] for cl in conceptLabels]\n",
    "\n",
    "    \n",
    "    #break  \n",
    "    #print(\"Check2\")\n",
    "    indices = []\n",
    "    #print(conceptLabels[0],conceptLabels[1])\n",
    "    for j in range(0,len(conceptLabels)):\n",
    "        indices.append([conceptBank.index(str(s)) for s in conceptLabels[j] if str(s) in conceptBank])\n",
    "   # print(\"Check3\")\n",
    "    \n",
    "    #break\n",
    "    #labelConcepts = torch.tensor(indices)\n",
    "    labelConcepts = [torch.tensor(lst, dtype=torch.long) for lst in indices]\n",
    "  \n",
    "    #print(labelConcepts)\n",
    " \n",
    "    #print(conceptLabelTensors)\n",
    "    if(imageTensorsTest is None):\n",
    "        imageTensorsTest = images\n",
    "        labelTensorsTest = labels\n",
    "        conceptLabelTensorsTest = labelConcepts\n",
    "    else:\n",
    "        imageTensorsTest = torch.cat((imageTensorsTest,images),0)\n",
    "        labelTensorsTest = torch.cat((labelTensorsTest,labels),0)\n",
    "        conceptLabelTensorsTest.extend(labelConcepts)\n",
    "    \n",
    "\n",
    "if(True):\n",
    "        torch.save(imageTensorsTest, 'imageTensorsTest.pt')\n",
    "        torch.save(labelTensorsTest, 'labelTensorsTest.pt')\n",
    "        torch.save(conceptLabelTensorsTest, 'conceptLabelTensorsTest.pt')\n",
    "        imageTensorsTest = None\n",
    "        labelTensorsTest = None\n",
    "        conceptLabelTensorsTest = None\n",
    "        gc.collect()\n",
    "\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTensorsTest = torch.load('imageTensorsTest.pt').to(device)\n",
    "labelTensorsTest = torch.load('labelTensorsTest.pt').to(device)\n",
    "conceptLabelTensorsTest = torch.load('conceptLabelTensorsTest.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "batchSize = 1\n",
    "\n",
    "predicted = []\n",
    "labelsList = []\n",
    "\n",
    "selectedConcepts = []\n",
    "cLabels = []\n",
    "\n",
    "conceptLearning = False\n",
    "classLearning = False\n",
    "\n",
    "pruneConcepts = False\n",
    "\n",
    "for e in range(0,epochs):\n",
    "\n",
    " acc = 0  \n",
    " running_loss = 0.0\n",
    " running_corrects = 0\n",
    " clLoss = []\n",
    " conLoss = []\n",
    "\n",
    " count = 0\n",
    " count1 = 0 \n",
    " \n",
    "\n",
    " for tdi in range(0,imageTensorsTest.shape[0],batchSize):\n",
    "\n",
    "    print(tdi)\n",
    "\n",
    "\n",
    "    if(tdi<20000):\n",
    "      \n",
    "      images = imageTensorsTest[count:count+batchSize].to(device)\n",
    "      labels = labelTensorsTest[count:count+batchSize].to(device)\n",
    "      labelConcepts =  conceptLabelTensorsTest[count:count+batchSize]\n",
    "      count = count + images.shape[0]\n",
    "      print(labelConcepts)\n",
    "\n",
    "\n",
    "    \n",
    "    images = images.to(torch.float32)\n",
    "\n",
    "    imageEmbeddings = imageEncoder(images).projected_global_embedding\n",
    "\n",
    "    \n",
    "\n",
    "    resOut = resNet(imageEmbeddings)\n",
    "\n",
    "    imageEmbeddings = 0.9*imageEmbeddings + 0.1*resOut\n",
    "\n",
    "    imageEmbeddings = nn.functional.normalize(imageEmbeddings, dim=-1)\n",
    "    \n",
    "\n",
    "    \n",
    "    conceptScores = torch.mm(imageEmbeddings,embeddingsCB.t())\n",
    "\n",
    "    output = fcNet(conceptScores)\n",
    "\n",
    "    #output = fcNet(imageEmbeddings)\n",
    "\n",
    "    \n",
    "\n",
    "    output = output.to(torch.float32)\n",
    "    labels = labels.to(torch.long)\n",
    "\n",
    "\n",
    "    predicted.extend(torch.argmax(output,dim=1).tolist())\n",
    "    labelsList.extend(labels.tolist())\n",
    "    \n",
    "    conceptScoresCopy = conceptScores.clone().detach().to(device)\n",
    "\n",
    "    maxValue =  torch.max(conceptScoresCopy,dim=1)[0]\n",
    "\n",
    "    \n",
    "    for i, idx in enumerate(labelConcepts):\n",
    "\n",
    "      conceptScoresCopy[i, idx] = torch.tensor(0.90)\n",
    "     \n",
    "    \n",
    "    #print(conceptScores,conceptScoresCopy)\n",
    "    #print(conceptScores.dtype,conceptScoresCopy.dtype)\n",
    "\n",
    "    lossClassification = lossFunction(output, labels)\n",
    "\n",
    "    lossConcepts = lossFunctionConcepts(conceptScores,conceptScoresCopy)\n",
    "    #print(alpha * lossConcepts)\n",
    "    #loss = lossClassification + alpha * lossConcepts\n",
    "    if(conceptLearning):\n",
    "     loss = alpha*lossConcepts\n",
    "    elif(classLearning):\n",
    "      loss = lossClassification\n",
    "    else:\n",
    "      loss = lossClassification + alpha*lossConcepts\n",
    "\n",
    "    clLoss.append(lossClassification.item())\n",
    "    conLoss.append(lossConcepts.item())\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "\n",
    "    # loss.backward()\n",
    "   \n",
    "    # optimizer.step()\n",
    "\n",
    "    k = 30\n",
    "    values, indices = torch.topk(conceptScores, k)\n",
    "\n",
    "\n",
    "\n",
    "    if(tdi<20000):\n",
    "    \n",
    "\n",
    "     k = 30\n",
    "     if(pruneConcepts):\n",
    "        pruneK = 100\n",
    "        \n",
    "        values, indices = torch.topk(conceptScores, pruneK)\n",
    "        #print(indices)\n",
    "        \n",
    "        prunedConcepts = [] \n",
    "        for i in range(pruneK):\n",
    "          for j in range(i+1,pruneK):\n",
    "            #print(torch.cosine_similarity(embeddingsCB[indices[0][i]],embeddingsCB[indices[0][j]],dim=-1),conceptBank[indices[0][i]],conceptBank[indices[0][j]])\n",
    "            if(torch.cosine_similarity(embeddingsCB[indices[0][i]],embeddingsCB[indices[0][j]],dim=-1)>=0.94):\n",
    "                prunedConcepts.append(indices[0][j].item())\n",
    "        #print(prunedConcepts)\n",
    "        countK = 0\n",
    "        tempSConcepts = ''         \n",
    "        for i in range(pruneK):\n",
    "         if(indices[0][i].item() not in prunedConcepts):\n",
    "            \n",
    "            if(values[0][i].item()>0.5):\n",
    "              countK = countK + 1\n",
    "              print(conceptBank[indices[0][i].item()],values[0][i].item())\n",
    "            \n",
    "         if(countK>=k):\n",
    "            break\n",
    "\n",
    "                                  \n",
    "\n",
    "      \n",
    "    #print(indices)\n",
    "     tempList3 = ''\n",
    "     tempConcepts3 = []\n",
    "     for i in range(k):\n",
    "        if(values[0][i].item()>0.5):\n",
    "         tempList3 = tempList3 + conceptBank[indices[0][i].item()] + '\\n'\n",
    "         \n",
    "         #print(conceptBank[indices[0][i].item()],values[0][i].item())\n",
    "     selectedConcepts.append(tempList3)\n",
    "     #print(\"----------------\")\n",
    "\n",
    "     tempList4=''\n",
    "     tempConcepts4 = []\n",
    "     for i in labelConcepts[0]:\n",
    "        tempList4 = tempList4 + str(conceptBank[i.item()]) + '\\n'\n",
    "        #print(conceptBank[i.item()])\n",
    "     cLabels.append(tempList4)   \n",
    "    \n",
    "     #print(\"-------------------------------------------------------------------\")\n",
    "     #break\n",
    "   \n",
    "     \n",
    "  \n",
    "    \n",
    "\n",
    "    running_loss += lossConcepts.item()\n",
    "\n",
    "\n",
    "    #running_corrects += torch.sum(torch.argmax(output, dim=1) == labels).item()\n",
    "\n",
    "\n",
    "    \n",
    "    acc = acc + torch.sum(torch.argmax(output,dim=1) == labels).item()\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    " print(\"Accuracy: \", acc/imageTensorsTest.shape[0],\"Loss:\", running_loss/imageTensorsTest.shape[0])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedConcepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fcNet, 'fcNet1.pt')\n",
    "torch.save(imageEncoder, 'imageEncoder1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTensorsTest = torch.load('/data/bharat/XAI/preComp/testImageTensors.pt')\n",
    "labelTensorsTest = torch.load('/data/bharat/XAI/preComp/testLabelTensors.pt')\n",
    "conceptLabelTensorsTest = torch.load('/data/bharat/XAI/preComp/testConceptLabelTensors.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2999, 3, 512, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageTensorsTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "# Assuming hypotheses and references are your sets of sentences\n",
    "\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "# Compute ROUGE scores for each pair of sentences\n",
    "scores = [rouge.get_scores(hyp, ref,avg=False) for hyp, ref in zip(selectedConcepts, cLabels)]\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.7386320399292163, 'p': 0.20185426670577797, 'f': 0.30973748088374436}, 'rouge-2': {'r': 0.49789618921502454, 'p': 0.07605868649141383, 'f': 0.12928144271809633}, 'rouge-l': {'r': 0.7384946178963695, 'p': 0.20181303249592353, 'f': 0.3096744791572917}}\n"
     ]
    }
   ],
   "source": [
    "totals = {\n",
    "    'rouge-1': {'r': 0, 'p': 0, 'f': 0},\n",
    "    'rouge-2': {'r': 0, 'p': 0, 'f': 0},\n",
    "    'rouge-l': {'r': 0, 'p': 0, 'f': 0}\n",
    "}\n",
    "\n",
    "# Count the number of items\n",
    "num_items = len(rouge_scores)\n",
    "\n",
    "# Sum up all scores\n",
    "for item in rouge_scores:\n",
    "    for rouge_key, scores in item[0].items():\n",
    "        for score_key, score_value in scores.items():\n",
    "            totals[rouge_key][score_key] += score_value\n",
    "\n",
    "# Calculate averages\n",
    "averages = {rouge_key: {score_key: score_value / num_items for score_key, score_value in scores.items()} for rouge_key, scores in totals.items()}\n",
    "\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/csgrad/byalavar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/csgrad/byalavar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Score: 0.2756530100674194\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Ensure the necessary NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the METEOR score accumulator\n",
    "score = 0\n",
    "\n",
    "# Assuming 'selectedConcepts' and 'cLabels' are defined and have the same length\n",
    "for i in range(len(selectedConcepts)):\n",
    "\t# Tokenize both the reference and the hypothesis\n",
    "\treference_tokens = word_tokenize(cLabels[i])\n",
    "\thypothesis_tokens = word_tokenize(selectedConcepts[i])\n",
    "\t\n",
    "\t# Calculate and accumulate the METEOR score\n",
    "\tscore += meteor_score([reference_tokens], hypothesis_tokens)\n",
    "\n",
    "# Calculate the average METEOR score\n",
    "average_score = score / len(selectedConcepts)\n",
    "print(f\"METEOR Score: {average_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
